# Gender Classification of Multilingual Twitter Data Using Individual Textual Features
## Data folder setup
1. In the Data folder, create 3 folders: Original, Training, Partitions.
2. In the Original folder, create 4 language folders: DE, FR, IT, NL. Each of them needs to contain a Tweets csv and a gender info txt like this: de_gender_info.txt / tweets-de.csv, corresponding to the language code. The data we used is formatted based on the Twisty Corpus.
## Instructions on how to run the project
1. To prepare the data for training/testing, first run the **<span style="color:red;">CV module</span>** in the Code folder.
2. Pick a *language*. You have to enter one *language code* from the following:
**de=German / fr=French / it=Italian / nl=Dutch**.
3. Enter *the number of training intances*. This is done in consideration of the running time. The results in the paper are based on **10,000 instances**. After that it will create 10 testing and 10 training partitions for the chosen language (in the Data -> Partitions folder). You need to do it four times if you want to use all language options.
4. Run the **<span style="color:red;">Main module</span>** in the Code folder. Note that it doesn’t loop.
5. Pick a *language*. You have to enter one *language code* just like in the CV module. Please make sure that the training files of chosen language have been generated by CV module.
6. Pick a *testing fold number* (1-10): it determines what part of the data will be used for testing e.g. 1 = first 10%, the rest is used for training (10-fold cross validation) without the limitation of training instances. Since we have set the limitation of training instances, so only the the first 10,000 instances (consistent with our paper) in the rest will be kept. This is where the files created by CV come into play.
7. Pick a *classification approach*: (1=NB / 2=SVM).
8. Decide if the tweets of a user should be *concatenated*: (1=Yes / 2=No). Originally we identified each tweet of a user individually and determined the gender using majority rule. Concatenation means the user's tweets are considered as a single long tweet and we classify the gender based on the single concatenated tweet.
9. Create and save training data: say “Y” in most cases. Only say “N” when repeating an experiment option with a particular fold that you have run before. This is used when testing code to save a bit of time.

**Further explanation:** 
Normally we need to read the csv file and get the text & gender of tweets, then turn them into tuples to train the NB model, but repeating this takes a long time. We decided to save the training tuples in a text file (in the Data -> Training folder) and then make the app read the text file. This means when repeating the same experiment, the app can just read the text file directly instead of preprocessing the csv, but obviously if you haven’t run the experiment before, it will throw an error because it can’t find the text file (exact combination of experiment + fold).

10. Wait a bit (should take about 1 minute) and the macro-averaged F1 score should be printed on the console along with the Male/Female precision and recall.
11. Only for SVM: try *non-linear SVM*. **Comment** linear SVC and **uncomment** non-linear SVM in the next line:
```python
# SVM = svm.LinearSVC(dual=False)
SVM = svm.SVC(kernel='rbf', gamma=0.5)
```
12. Try other non-linear SVM *kernels* and *gamma values* to optimize the final result: e.g.  `SVM = svm.SVC(kernel='poly', gamma=1)`

## Design decisions
- We use Naive Bayes and SVM to classify tweets as Male/Female. The NB model is trained with tuples of tweet (text) + gender (obtained by checking the user info file). As for the SVM model, we use `svm` in the library `sklearn`, the training and testing process is same as NB.
- To test our model, we create a list of User class objects (from the provided data) and give them a limited number (20) of their own tweets (we match the @handle in our data), classify those
tweets, and then based on the majority class, label that user as Male/Female.
- We calculate the F1 score for both classes and macro-average it to evaluate our model’s performance.
